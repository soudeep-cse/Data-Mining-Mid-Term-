# -*- coding: utf-8 -*-
"""Copy of Mid(DM).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m68GGkO_xzWgES3FJjfJD0FkvGDY8D4U
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler


data = pd.read_csv('/content/winequality-white.csv')


print("Missing values before preprocessing:")
print(data.isnull().sum())
data = data.dropna()


duplicate_rows = data[data.duplicated()]
print("Duplicate rows before preprocessing:")
print(duplicate_rows)
data = data.drop_duplicates()



print("Missing values after preprocessing:")
print(data.isnull().sum())

duplicate_rows_after = data[data.duplicated()]
print("Duplicate rows after preprocessing:", duplicate_rows_after)

correlation_matrix = data.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Correlation Matrix Heatmap')
plt.show()

numeric_columns = data.select_dtypes(include=[np.number]).columns


for col in numeric_columns:
    plt.figure(figsize=(8, 6))
    sns.boxplot(x=data[col])
    plt.title(f'Before removing outliers from: {col}')
    plt.show()

def remove_outliers_iqr(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]

for col in numeric_columns:
    data = remove_outliers_iqr(data, col)

for col in numeric_columns:
    plt.figure(figsize=(8, 6))
    sns.boxplot(x=data[col])
    plt.title(f'After removing outliers from: {col}')
    plt.show()

X = data.drop('quality', axis=1)
y = data['quality']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

def euclidean_distance(point1, point2):
    return np.sqrt(np.sum((point1 - point2) ** 2))


def manhattan_distance(point1, point2):
    return np.sum(np.abs(point1 - point2))


def max_distance(point1, point2):
    return np.max(np.abs(point1 - point2))


a=3
b=5
c=7
d=9
e=12

n=c


def knn_predict(train_data, train_labels, test_data, k=n, distance_metric=euclidean_distance):
    predictions = []
    for test_point in test_data:
        distances = [distance_metric(test_point, train_point) for train_point in train_data]

        k_indices = np.argsort(distances)[:k]

        k_nearest_labels = train_labels.iloc[k_indices].tolist()

        most_common = Counter(k_nearest_labels).most_common()

        prediction = min(most_common, key=lambda x: (-x[1], x[0]))[0]

        predictions.append(prediction)

    return predictions


predictions_euclidean = knn_predict(X_train, y_train, X_test, k=n, distance_metric=euclidean_distance)

predictions_manhattan = knn_predict(X_train, y_train, X_test, k=n, distance_metric=manhattan_distance)

predictions_max = knn_predict(X_train, y_train, X_test, k=n, distance_metric=max_distance)


accuracy_euclidean = accuracy_score(y_test, predictions_euclidean)

accuracy_manhattan = accuracy_score(y_test, predictions_manhattan)

accuracy_max = accuracy_score(y_test, predictions_max)

print(f'Accuracy (Euclidean): {accuracy_euclidean:.2f}')
print(f'Accuracy (Manhattan): {accuracy_manhattan:.2f}')
print(f'Accuracy (Maximum): {accuracy_max:.2f}')


new_wine_sample = np.array([7.0, 1.5, 5.3, 2.0, 0.18, 20, 50, 0.995, 3.3, 0.6, 10.0]).reshape(1, -1)
predicted_quality_euclidean = knn_predict(X_train, y_train, new_wine_sample, k=n, distance_metric=euclidean_distance)
print(f'Predicted Quality(Euclidean): {predicted_quality_euclidean[0]}')


predicted_quality_manhattan = knn_predict(X_train, y_train, new_wine_sample, k=n, distance_metric=manhattan_distance)
print(f'Predicted Quality(Manhattan): {predicted_quality_manhattan[0]}')


predicted_quality_max = knn_predict(X_train, y_train, new_wine_sample, k=n, distance_metric=max_distance)
print(f'Predicted Quality(Maximum): {predicted_quality_max[0]}')

